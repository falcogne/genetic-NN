{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import ssl\n",
    "# ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# cifar = tf.keras.datasets.cifar100\n",
    "# (x_train, y_train), (x_test, y_test) = cifar.load_data()\n",
    "# model = tf.keras.applications.ResNet50(\n",
    "#     include_top=True,\n",
    "#     weights=None,\n",
    "#     input_shape=(32, 32, 3),\n",
    "#     classes=100,)\n",
    "\n",
    "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "# model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"accuracy\"])\n",
    "# model.fit(x_train, y_train, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 21:01:12.962121: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from keras import layers, models, optimizers, Input, Model\n",
    "from keras.models import load_model\n",
    "# import tensorflow_addons as tfa\n",
    "\n",
    "# from malleable_skeleton import MalleableLayer\n",
    "from genetic_network import GeneticNetwork1D, GeneticNetwork2D\n",
    "\n",
    "from evolution_training import EvolutionStructure, create_starter_population_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_after_training(history, added_title_text=\"\"):\n",
    "    # ['loss', 'acc', 'f1_score', 'precision', 'recall', 'auc', \\\n",
    "    # 'val_loss', 'val_acc', 'val_f1_score', 'val_precision', 'val_recall', 'val_auc']\n",
    "\n",
    "    for metric_name in ['loss', 'acc', 'f1_score', 'precision', 'recall', 'auc']:\n",
    "        training_metric = history.history[metric_name]\n",
    "        val_metric = history.history[f\"val_{metric_name}\"]\n",
    "        epochs = range(1, len(training_metric)+1)\n",
    "\n",
    "        plt.plot(epochs, training_metric, 'bo', label=f'Training {metric_name}')\n",
    "        plt.plot(epochs, val_metric, 'b', label=f'Validation {metric_name}')\n",
    "        plt.title(f'Training and validation {metric_name}{added_title_text}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def preprocess(sample, image_size, num_classes):\n",
    "    image = tf.image.resize(sample['image'], image_size) / 255.0  # Normalize\n",
    "    category = tf.one_hot(sample['label'], depth=num_classes)\n",
    "    return image, category\n",
    "\n",
    "def plot_prediction_result(test_image):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(test_image)\n",
    "    plt.title(\"Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "USE_2D_DATA = False\n",
    "\n",
    "EPOCHS=2\n",
    "ITERATIONS = 3\n",
    "\n",
    "HOURS =   0\n",
    "MINUTES = 5\n",
    "SECONDS = 30\n",
    "POPULATION_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 21:01:53.426804: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-01-27 21:01:53.426840: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-01-27 21:01:53.589115: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2025-01-27 21:01:53.589465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: AMD Radeon Pro 5500M\n",
      "Number of training batches:   1360\n",
      "Number of validation batches: 204\n"
     ]
    }
   ],
   "source": [
    "if USE_2D_DATA:\n",
    "    LOSS_STR='categorical_crossentropy'\n",
    "    ACTIVATION_STR='softmax'\n",
    "\n",
    "    dataset, info = tfds.load('cifar10', split=['train', 'test'], with_info=True, as_supervised=False)\n",
    "    OUTPUT_SIZE = 10\n",
    "    INPUT_SHAPE = (32, 32, 3)\n",
    "    PATCH_NUM = (4,4)\n",
    "    DATASET_NAME = 'CIFAR-10'\n",
    "\n",
    "    # dataset, info = tfds.load('cifar100', split=['train', 'test'], with_info=True, as_supervised=False)\n",
    "    # OUTPUT_SIZE = 100\n",
    "    # INPUT_SHAPE = (32, 32)\n",
    "    # PATCH_NUM = (2,2)\n",
    "    # DATASET_NAME = 'CIFAR-100'\n",
    "\n",
    "    # tfds checksum does not pass for this one for some reason\n",
    "    # dataset, info = tfds.load('caltech101', split=['train', 'test'], with_info=True, as_supervised=False)\n",
    "    # # OUTPUT_SIZE = 101\n",
    "    # # INPUT_SHAPE = (128, 128)\n",
    "    # PATCH_NUM = (8,8)\n",
    "    # # DATASET_NAME = 'caltech 101'\n",
    "\n",
    "    # dataset, info = tfds.load('imagenette', split=['train', 'validation'], with_info=True, as_supervised=False)\n",
    "    # OUTPUT_SIZE = 10\n",
    "    # INPUT_SHAPE = (160, 160)\n",
    "    # PATCH_NUM = (10,10)\n",
    "    # DATASET_NAME = 'tiny imagenet'\n",
    "\n",
    "    # all_imgnet, info = tfds.load('imagenet2012', split='train', shuffle_files=True, as_supervised=False)\n",
    "    # dataset = all_imgnet.take(5_000)\n",
    "    # # INPUT_SHAPE = (128, 128)\n",
    "    # PATCH_NUM = (8,8)\n",
    "    # OUTPUT_SIZE=None\n",
    "    # DATASET_NAME = 'imagenet'\n",
    "\n",
    "\n",
    "    train_dataset = dataset[0]\n",
    "    test_dataset = dataset[1]\n",
    "\n",
    "    # Convert the train dataset to NumPy arrays\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "\n",
    "    for sample in tfds.as_numpy(train_dataset.map(lambda sample: preprocess(sample, INPUT_SHAPE[:2], OUTPUT_SIZE))):\n",
    "        train_images.append(sample[0])\n",
    "        train_labels.append(sample[1])\n",
    "\n",
    "    train_images = np.array(train_images)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    # Split the data using train_test_split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.13, random_state=42)\n",
    "\n",
    "    # Create TensorFlow datasets\n",
    "    train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(1024).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    val_data = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Process the test dataset\n",
    "    test_data = test_dataset.map(lambda sample: preprocess(sample, INPUT_SHAPE[:2], OUTPUT_SIZE)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Print dataset sizes\n",
    "    print(f\"Number of training batches:   {len(train_data)}\")\n",
    "    print(f\"Number of validation batches: {len(val_data)}\")\n",
    "\n",
    "else:\n",
    "    LOSS_STR='binary_crossentropy'\n",
    "    ACTIVATION_STR='sigmoid'\n",
    "\n",
    "    # Load the data\n",
    "    data = pd.read_csv('titanic-model/train.csv')\n",
    "\n",
    "    # Fill missing values (this is just an example; you may use other imputation methods)\n",
    "    data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "    # data['Fare'].fillna(data['Fare'].median(), inplace=True)\n",
    "    # data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    categorical_features = ['Sex', 'Embarked']\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    encoded_features = encoder.fit_transform(data[categorical_features])\n",
    "\n",
    "    # Normalize numerical features\n",
    "    numerical_features = ['Pclass', 'Age', 'Fare', 'SibSp', 'Parch']\n",
    "    scaler = StandardScaler()\n",
    "    normalized_features = scaler.fit_transform(data[numerical_features])\n",
    "\n",
    "    # Combine features\n",
    "    X = np.concatenate([encoded_features, normalized_features], axis=1)\n",
    "    y = data['Survived'].values\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    INPUT_SHAPE = X_train.shape[1:]\n",
    "    OUTPUT_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 100)       2800      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 102400)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1024010   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,026,810\n",
      "Trainable params: 1,026,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 21:02:24.175817: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-01-27 21:02:24.224665: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1360/1360 [==============================] - 32s 22ms/step - loss: 1.4781 - acc: 0.4835 - precision: 0.7009 - recall: 0.2546 - auc: 0.8735     \n",
      "Epoch 2/5\n",
      "1360/1360 [==============================] - 30s 22ms/step - loss: 1.1594 - acc: 0.6009 - precision: 0.7547 - recall: 0.4292 - auc: 0.9234\n",
      "Epoch 3/5\n",
      "1360/1360 [==============================] - 30s 22ms/step - loss: 1.0203 - acc: 0.6486 - precision: 0.7778 - recall: 0.5059 - auc: 0.9405\n",
      "Epoch 4/5\n",
      "1360/1360 [==============================] - 31s 22ms/step - loss: 0.9110 - acc: 0.6861 - precision: 0.8013 - recall: 0.5644 - auc: 0.9525\n",
      "Epoch 5/5\n",
      "1360/1360 [==============================] - 30s 22ms/step - loss: 0.7976 - acc: 0.7281 - precision: 0.8285 - recall: 0.6225 - auc: 0.9634\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    # model = models.Sequential([\n",
    "    #     layers.Conv2D(100, (3, 3), activation='relu', padding='same'),\n",
    "    #     layers.Flatten(),\n",
    "    #     layers.Dense(OUTPUT_SIZE, activation=ACTIVATION_STR),\n",
    "    # ])\n",
    "    # Create the model using x = and layers\n",
    "    inputs = layers.Input(shape=INPUT_SHAPE)  # Define the input layer\n",
    "    x = layers.Conv2D(100, (3, 3), activation='relu', padding='same')(inputs)  # Conv2D layer\n",
    "    x = layers.Flatten()(x)  # Flatten the output from Conv2D\n",
    "    x = layers.Dense(OUTPUT_SIZE, activation=ACTIVATION_STR)(x)  # Dense layer with output activation\n",
    "\n",
    "    # Create the final model\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    # Model summary to visualize the structure\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=LOSS_STR,\n",
    "        metrics=[\n",
    "            'acc',\n",
    "            # tfa.metrics.F1Score(num_classes=OUTPUT_SIZE, average='weighted'),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            tf.keras.metrics.AUC()\n",
    "        ]\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=5,\n",
    "        verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = [\n",
    "    (\n",
    "    create_starter_population_entry(\n",
    "        GeneticNetwork2D(input_shape=INPUT_SHAPE, output_features=OUTPUT_SIZE, output_activation_str=ACTIVATION_STR,)\n",
    "    ) if USE_2D_DATA else\n",
    "    create_starter_population_entry(\n",
    "        GeneticNetwork1D(input_shape=INPUT_SHAPE, output_features=OUTPUT_SIZE, output_activation_str=ACTIVATION_STR,)\n",
    "    )\n",
    "    ) for _ in range(POPULATION_SIZE)\n",
    "]\n",
    "\n",
    "evolution = EvolutionStructure(\n",
    "    population,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    optimizer_str='adam',\n",
    "    loss_str=LOSS_STR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--ITERATION 0 out of 3--\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "<0><0><0><0><0><0><0><0><0><0><0><0><0><0><0><0><0><0><0><0>\n",
      "network rank None (done with 0 epochs)\n",
      "network fitness None\n",
      "GeneticNetwork:\n",
      "Input shape: (32, 32, 3)\n",
      "Convolution base:\n",
      "seq:\n",
      "[TerminalLayer2D(type=Conv2D, vector_rep=ListWrapper([2, 68, 3, 1, 0]))]\n",
      "Feedforward network:\n",
      "seq:\n",
      "[TerminalLayer1D(type=Dropout, vector_rep=ListWrapper([0, 0.5, 216, 7, 0]))]\n",
      "Output:\n",
      "<keras.src.layers.core.dense.Dense object at 0x7fd4313bc550>\n",
      "\n",
      "\n",
      "<1><1><1><1><1><1><1><1><1><1><1><1><1><1><1><1><1><1><1><1>\n",
      "network rank None (done with 0 epochs)\n",
      "network fitness None\n",
      "GeneticNetwork:\n",
      "Input shape: (32, 32, 3)\n",
      "Convolution base:\n",
      "seq:\n",
      "[TerminalLayer2D(type=BatchNormalization, vector_rep=ListWrapper([1, 22, 5, 2, 0]))]\n",
      "Feedforward network:\n",
      "seq:\n",
      "[TerminalLayer1D(type=Dense, vector_rep=ListWrapper([2, 0.7, 170, 5, 0]))]\n",
      "Output:\n",
      "<keras.src.layers.core.dense.Dense object at 0x7fd471d98880>\n",
      "\n",
      "\n",
      "<2><2><2><2><2><2><2><2><2><2><2><2><2><2><2><2><2><2><2><2>\n",
      "network rank None (done with 0 epochs)\n",
      "network fitness None\n",
      "GeneticNetwork:\n",
      "Input shape: (32, 32, 3)\n",
      "Convolution base:\n",
      "seq:\n",
      "[TerminalLayer2D(type=BatchNormalization, vector_rep=ListWrapper([1, 78, 1, 3, 2]))]\n",
      "Feedforward network:\n",
      "seq:\n",
      "[TerminalLayer1D(type=Dense, vector_rep=ListWrapper([2, 0.7, 116, 7, 1]))]\n",
      "Output:\n",
      "<keras.src.layers.core.dense.Dense object at 0x7fd4213c73d0>\n",
      "\n",
      "\n",
      "<3><3><3><3><3><3><3><3><3><3><3><3><3><3><3><3><3><3><3><3>\n",
      "network rank None (done with 0 epochs)\n",
      "network fitness None\n",
      "GeneticNetwork:\n",
      "Input shape: (32, 32, 3)\n",
      "Convolution base:\n",
      "seq:\n",
      "[TerminalLayer2D(type=Conv2D, vector_rep=ListWrapper([2, 5, 7, 3, 0]))]\n",
      "Feedforward network:\n",
      "seq:\n",
      "[TerminalLayer1D(type=BatchNormalization, vector_rep=ListWrapper([1, 0.9, 136, 7, 1]))]\n",
      "Output:\n",
      "<keras.src.layers.core.dense.Dense object at 0x7fd4213d2bb0>\n",
      "\n",
      "\n",
      "<4><4><4><4><4><4><4><4><4><4><4><4><4><4><4><4><4><4><4><4>\n",
      "network rank None (done with 0 epochs)\n",
      "network fitness None\n",
      "GeneticNetwork:\n",
      "Input shape: (32, 32, 3)\n",
      "Convolution base:\n",
      "seq:\n",
      "[TerminalLayer2D(type=Conv2D, vector_rep=ListWrapper([2, 62, 5, 2, 0]))]\n",
      "Feedforward network:\n",
      "seq:\n",
      "[TerminalLayer1D(type=BatchNormalization, vector_rep=ListWrapper([1, 0.9, 97, 3, 2]))]\n",
      "Output:\n",
      "<keras.src.layers.core.dense.Dense object at 0x7fd431476190>\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "TRAINING POPULATION ...\n",
      "Epoch 1/2\n",
      "1360/1360 [==============================] - 51s 37ms/step - loss: 4.3357 - acc: 0.1951 - precision: 0.2193 - recall: 0.1198 - auc: 0.6144\n",
      "Epoch 2/2\n",
      "1360/1360 [==============================] - 63s 46ms/step - loss: 2.4366 - acc: 0.2658 - precision: 0.3389 - recall: 0.1351 - auc: 0.7050\n",
      "Epoch 1/2\n",
      " 318/1360 [======>.......................] - ETA: 21s - loss: 1.9029 - acc: 0.3318 - precision_1: 0.5784 - recall_1: 0.0721 - auc_1: 0.7723"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--ITERATION \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mITERATIONS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m--\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mevolution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterate_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   <All done with iterating>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/genetic-NN/evolution_training.py:166\u001b[0m, in \u001b[0;36mEvolutionStructure.iterate_population\u001b[0;34m(self, train_epochs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTRAINING POPULATION ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEVALUATING POPULATION ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/genetic-NN/evolution_training.py:77\u001b[0m, in \u001b[0;36mEvolutionStructure.train_population\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epochs_to_do \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# already trained don't need to do more\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_reps\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m epochs_done \u001b[38;5;241m+\u001b[39m epochs_to_do\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seconds_to_run = HOURS*60*60+MINUTES*60+SECONDS\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(ITERATIONS):\n",
    "    if time.time() - start_time > seconds_to_run:\n",
    "        break\n",
    "    print(f\"\\n\\n--ITERATION {i} out of {ITERATIONS}--\\n\\n\")\n",
    "    evolution.iterate_population(train_epochs=EPOCHS)\n",
    "\n",
    "print(\"\\n   <All done with iterating>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.6112 - acc: 0.6966 - precision_8: 0.6781 - recall_8: 0.3694 - auc_8: 0.7491     \n",
      "Epoch 2/2\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5206 - acc: 0.7683 - precision_8: 0.8503 - recall_8: 0.4664 - auc_8: 0.8360\n",
      "Epoch 1/2\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.6151 - acc: 0.6826 - precision_9: 0.6029 - recall_9: 0.4590 - auc_9: 0.7440\n",
      "Epoch 2/2\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5150 - acc: 0.7612 - precision_9: 0.8551 - recall_9: 0.4403 - auc_9: 0.8369\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4765 - acc: 0.7765 - precision_8: 0.8542 - recall_8: 0.5541 - auc_8: 0.8893\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4704 - acc: 0.7821 - precision_9: 0.8571 - recall_9: 0.5676 - auc_9: 0.8865\n",
      "{'network': <genetic_network.GeneticNetwork1D object at 0x7f91215797f0>, 'model': <keras.engine.functional.Functional object at 0x7f91215879d0>, 'compiled': True, 'training_reps': 2, 'rank': None, 'fitness': -0.470369815826416, 'stats': [0.470369815826416, 0.7821229100227356, 0.8571428656578064, 0.5675675868988037, 0.8864864706993103]}\n",
      "{'network': <genetic_network.GeneticNetwork1D object at 0x7f916a2a6280>, 'model': <keras.engine.functional.Functional object at 0x7f91295e83d0>, 'compiled': True, 'training_reps': 2, 'rank': 0, 'fitness': -0.47619006037712097, 'stats': [0.47619006037712097, 0.7709497213363647, 0.8367347121238708, 0.5540540814399719, 0.8867438435554504]}\n",
      "{'network': <genetic_network.GeneticNetwork1D object at 0x7f916a6ce640>, 'model': <keras.engine.functional.Functional object at 0x7f91214355e0>, 'compiled': True, 'training_reps': 2, 'rank': None, 'fitness': -0.47648340463638306, 'stats': [0.47648340463638306, 0.7765362858772278, 0.8541666865348816, 0.5540540814399719, 0.8893179297447205]}\n",
      "{'network': <genetic_network.GeneticNetwork1D object at 0x7f916a139640>, 'model': <keras.engine.functional.Functional object at 0x7f90f9aee190>, 'compiled': True, 'training_reps': 2, 'rank': 1, 'fitness': -0.5002744793891907, 'stats': [0.5002744793891907, 0.7541899681091309, 0.8409090638160706, 0.5, 0.8658300638198853]}\n",
      "\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "\n",
      "Network Ranked #1:\n",
      "With a fitness of -0.470369815826416 after 2 epochs...\n",
      "GeneticNetwork:\n",
      "Malleable Layer:\n",
      "seq:\n",
      "[TerminalLayer1D(type=Dense, vector_rep=ListWrapper([2, 0.1, 235, 3, 2]))]\n",
      "Output:\n",
      "<keras.layers.core.dense.Dense object at 0x7f91215871f0>\n",
      "\n",
      "\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "\n",
      "Network Ranked #2:\n",
      "With a fitness of -0.47619006037712097 after 2 epochs...\n",
      "GeneticNetwork:\n",
      "Malleable Layer:\n",
      "seq:\n",
      "[TerminalLayer1D(type=BatchNormalization, vector_rep=ListWrapper([1, 0.3, 128, 7, 2]))\n",
      "TerminalLayer1D(type=Dense, vector_rep=ListWrapper([2, 0.1, 235, 3, 2]))]\n",
      "Output:\n",
      "<keras.layers.core.dense.Dense object at 0x7f91295e8070>\n",
      "\n",
      "\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "\n",
      "Network Ranked #3:\n",
      "With a fitness of -0.47648340463638306 after 2 epochs...\n",
      "GeneticNetwork:\n",
      "Malleable Layer:\n",
      "seq:\n",
      "[TerminalLayer1D(type=Dense, vector_rep=ListWrapper([2, 0.1, 235, 3, 2]))]\n",
      "Output:\n",
      "<keras.layers.core.dense.Dense object at 0x7f90f9e17760>\n",
      "\n",
      "\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "\n",
      "Network Ranked #4:\n",
      "With a fitness of -0.5002744793891907 after 2 epochs...\n",
      "GeneticNetwork:\n",
      "Malleable Layer:\n",
      "seq:\n",
      "[TerminalLayer1D(type=Dense, vector_rep=ListWrapper([2, 0.1, 235, 3, 2]))]\n",
      "Output:\n",
      "<keras.layers.core.dense.Dense object at 0x7f90f9aeb0d0>\n",
      "\n",
      "loss, accuracy, precision, recall, auc\n",
      "[[0.5207383632659912, 0.7541899681091309, 0.8947368264198303, 0.45945945382118225, 0.8761904835700989], [0.5995364189147949, 0.6759776473045349, 0.8636363744735718, 0.2567567527294159, 0.8289575576782227], [0.9715566039085388, 0.25139665603637695, 0.21698112785816193, 0.31081080436706543, 0.25231659412384033], [0.5002744793891907, 0.7541899681091309, 0.8409090638160706, 0.5, 0.8658300638198853]]\n",
      "[[0.5002744793891907, 0.7541899681091309, 0.8409090638160706, 0.5, 0.8658300638198853], [0.5207383632659912, 0.7541899681091309, 0.8947368264198303, 0.45945945382118225, 0.8761904835700989], [0.47619006037712097, 0.7709497213363647, 0.8367347121238708, 0.5540540814399719, 0.8867438435554504], [0.5596101880073547, 0.7374301552772522, 0.7288135886192322, 0.5810810923576355, 0.8415701389312744]]\n",
      "[[0.47619006037712097, 0.7709497213363647, 0.8367347121238708, 0.5540540814399719, 0.8867438435554504], [0.5002744793891907, 0.7541899681091309, 0.8409090638160706, 0.5, 0.8658300638198853], [0.5953312516212463, 0.6871508359909058, 1.0, 0.2432432472705841, 0.8830115795135498], [0.6140199899673462, 0.7094972133636475, 1.0, 0.29729729890823364, 0.8552767038345337]]\n",
      "[[0.47619006037712097, 0.7709497213363647, 0.8367347121238708, 0.5540540814399719, 0.8867438435554504], [0.5002744793891907, 0.7541899681091309, 0.8409090638160706, 0.5, 0.8658300638198853], [0.47648340463638306, 0.7765362858772278, 0.8541666865348816, 0.5540540814399719, 0.8893179297447205], [0.470369815826416, 0.7821229100227356, 0.8571428656578064, 0.5675675868988037, 0.8864864706993103]]\n",
      "\n",
      " best fitness stats over iterations:\n",
      "loss, accuracy, precision, recall, auc\n",
      "[0.5002744793891907, 0.7541899681091309, 0.8409090638160706, 0.5, 0.8658300638198853]\n",
      "[0.47619006037712097, 0.7709497213363647, 0.8367347121238708, 0.5540540814399719, 0.8867438435554504]\n",
      "[0.47619006037712097, 0.7709497213363647, 0.8367347121238708, 0.5540540814399719, 0.8867438435554504]\n",
      "[0.470369815826416, 0.7821229100227356, 0.8571428656578064, 0.5675675868988037, 0.8864864706993103]\n"
     ]
    }
   ],
   "source": [
    "evolution.train_population(epochs=EPOCHS)\n",
    "evolution.calculate_fitness()\n",
    "evolution.rank_population()\n",
    "for d in evolution.population:\n",
    "    network, epochs_done, rank, fitness, stats = d['network'], d['training_reps'], d['rank'], d['fitness'], d['stats']\n",
    "    print()\n",
    "    print(\"-*\"*80 + \"-\")\n",
    "    print(f\"\\nNetwork Ranked #{rank+1}:\")\n",
    "    print(f\"With a fitness of {fitness} after {epochs_done} epochs...\")\n",
    "    print(network)\n",
    "\n",
    "\n",
    "print(\"loss, accuracy, precision, recall, auc\")\n",
    "for ele in evolution.all_stats:\n",
    "    print(ele)\n",
    "print(\"\\n best fitness stats over iterations:\")\n",
    "print(\"loss, accuracy, precision, recall, auc\")\n",
    "for ele in evolution.best_stats:\n",
    "    print(ele)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
