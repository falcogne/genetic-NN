{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-18 23:08:05.165853: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from keras import layers, models, optimizers, Input, Model\n",
    "from keras.models import load_model\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from malleable_network import GeneticNetwork\n",
    "from genetic_training import EvolutionStructure, create_starter_population_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_after_training(history, added_title_text=\"\"):\n",
    "    # ['loss', 'acc', 'f1_score', 'precision', 'recall', 'auc', \\\n",
    "    # 'val_loss', 'val_acc', 'val_f1_score', 'val_precision', 'val_recall', 'val_auc']\n",
    "\n",
    "    for metric_name in ['loss', 'acc', 'f1_score', 'precision', 'recall', 'auc']:\n",
    "        training_metric = history.history[metric_name]\n",
    "        val_metric = history.history[f\"val_{metric_name}\"]\n",
    "        epochs = range(1, len(training_metric)+1)\n",
    "\n",
    "        plt.plot(epochs, training_metric, 'bo', label=f'Training {metric_name}')\n",
    "        plt.plot(epochs, val_metric, 'b', label=f'Validation {metric_name}')\n",
    "        plt.title(f'Training and validation {metric_name}{added_title_text}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def preprocess(sample, image_size, num_classes):\n",
    "    image = tf.image.resize(sample['image'], image_size) / 255.0  # Normalize\n",
    "    category = tf.one_hot(sample['label'], depth=num_classes)\n",
    "    return image, category\n",
    "\n",
    "def plot_prediction_result(test_image):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(test_image)\n",
    "    plt.title(\"Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    dataset, info = tfds.load('cifar10', split=['train', 'test'], with_info=True, as_supervised=False)\n",
    "    OUTPUT_SIZE = 10\n",
    "    IMG_SIZE = (32, 32)\n",
    "    PATCH_NUM = (4,4)\n",
    "    DATASET_NAME = 'CIFAR-10'\n",
    "\n",
    "    # dataset, info = tfds.load('cifar100', split=['train', 'test'], with_info=True, as_supervised=False)\n",
    "    # OUTPUT_SIZE = 100\n",
    "    # IMG_SIZE = (32, 32)\n",
    "    # PATCH_NUM = (2,2)\n",
    "    # DATASET_NAME = 'CIFAR-100'\n",
    "\n",
    "    # tfds checksum does not pass for this one for some reason\n",
    "    # dataset, info = tfds.load('caltech101', split=['train', 'test'], with_info=True, as_supervised=False)\n",
    "    # # OUTPUT_SIZE = 101\n",
    "    # # IMG_SIZE = (128, 128)\n",
    "    # PATCH_NUM = (8,8)\n",
    "    # # DATASET_NAME = 'caltech 101'\n",
    "\n",
    "    # dataset, info = tfds.load('imagenette', split=['train', 'validation'], with_info=True, as_supervised=False)\n",
    "    # OUTPUT_SIZE = 10\n",
    "    # IMG_SIZE = (160, 160)\n",
    "    # PATCH_NUM = (10,10)\n",
    "    # DATASET_NAME = 'tiny imagenet'\n",
    "\n",
    "    # all_imgnet, info = tfds.load('imagenet2012', split='train', shuffle_files=True, as_supervised=False)\n",
    "    # dataset = all_imgnet.take(5_000)\n",
    "    # # IMG_SIZE = (128, 128)\n",
    "    # PATCH_NUM = (8,8)\n",
    "    # OUTPUT_SIZE=None\n",
    "    # DATASET_NAME = 'imagenet'\n",
    "\n",
    "\n",
    "    train_dataset = dataset[0]\n",
    "    test_dataset = dataset[1]\n",
    "\n",
    "    for sample in train_dataset.take(4):\n",
    "        # print(list(sample.keys()))\n",
    "        # print(sample['id'])\n",
    "        # print(sample['image'][:5])\n",
    "        # print(sample['label'])\n",
    "        image = tf.image.convert_image_dtype(sample['image'], tf.float32)\n",
    "        print(f\"Image shape: {image.shape}\")\n",
    "        print(f\"Label (class): {sample['label']}\")\n",
    "\n",
    "    full_train_data = train_dataset.map(lambda sample: preprocess(sample, IMG_SIZE, OUTPUT_SIZE)).shuffle(1024).batch(BATCH_SIZE)\n",
    "\n",
    "    validation_split = 0.13\n",
    "    num_train = int((1 - validation_split) * info.splits['train'].num_examples / BATCH_SIZE)\n",
    "    print(f\"number training batches:   {num_train}\")\n",
    "    print(f\"number validation batches: {int(info.splits['train'].num_examples / BATCH_SIZE - num_train)}\")\n",
    "\n",
    "    train_data = full_train_data.take(num_train).prefetch(tf.data.AUTOTUNE)\n",
    "    val_data = full_train_data.skip(num_train).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    test_data = test_dataset.map(lambda sample: preprocess(sample, IMG_SIZE, OUTPUT_SIZE)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/afalcignombp/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Fill missing values (this is just an example; you may use other imputation methods)\n",
    "# data['age'].fillna(data['age'].median(), inplace=True)\n",
    "# data['fare'].fillna(data['fare'].median(), inplace=True)\n",
    "# data['embarked'].fillna(data['embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categorical_features = ['Sex', 'Embarked']\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_features = encoder.fit_transform(data[categorical_features])\n",
    "\n",
    "# Normalize numerical features\n",
    "numerical_features = ['Pclass', 'Age', 'Fare', 'SibSp', 'Parch']\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(data[numerical_features])\n",
    "\n",
    "# Combine features\n",
    "X = np.concatenate([encoded_features, normalized_features], axis=1)\n",
    "y = data['Survived'].values\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "INPUT_SHAPE = X_train.shape[1:]\n",
    "OUTPUT_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = [\n",
    "    create_starter_population_entry(GeneticNetwork(\n",
    "        input_shape=INPUT_SHAPE,\n",
    "        output_features=OUTPUT_SIZE,\n",
    "        output_activation_str=\"sigmoid\",\n",
    "    ))\n",
    "    for _ in range(4)\n",
    "]\n",
    "\n",
    "evolution = EvolutionStructure(\n",
    "    population,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    optimizer_str='adam',\n",
    "    loss_str='binary_crossentropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population before:\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 1s 1ms/step - loss: nan - acc: 0.6166 - precision_4: 0.1429 - recall_4: 0.0037 - auc_4: 4.2020e-04\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 0s 3ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 1s 1ms/step - loss: nan - acc: 0.6180 - precision_5: 0.3889 - recall_5: 0.0261 - auc_5: 8.3619e-04\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 1s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.5000 - recall_6: 0.0261 - auc_6: 0.0011\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 0s 2ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 1s 1ms/step - loss: nan - acc: 0.6222 - precision_7: 0.4000 - recall_7: 0.0075 - auc_7: 6.0088e-04\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 0s 1ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 0s 3ms/step - loss: nan - acc: 0.6236 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "6/6 [==============================] - 0s 2ms/step - loss: nan - acc: 0.5866 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - auc_4: 0.0000e+00\n",
      "6/6 [==============================] - 0s 2ms/step - loss: nan - acc: 0.5866 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.0000e+00\n",
      "6/6 [==============================] - 0s 2ms/step - loss: nan - acc: 0.5866 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - auc_6: 0.0000e+00\n",
      "6/6 [==============================] - 0s 2ms/step - loss: nan - acc: 0.5866 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - auc_7: 0.0000e+00\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f78194f4d60>, 'training_reps': 20, 'rank': None, 'fitness': nan}\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f7819508700>, 'training_reps': 20, 'rank': None, 'fitness': nan}\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f78195172b0>, 'training_reps': 20, 'rank': None, 'fitness': nan}\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f781950dbe0>, 'training_reps': 20, 'rank': None, 'fitness': nan}\n",
      "deleted 2 elements from population\n",
      "population is back to 4 networks\n",
      "population after:\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "population before:\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f78194f4d60>, 'training_reps': 20, 'rank': 0, 'fitness': nan}\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f7819508700>, 'training_reps': 20, 'rank': 1, 'fitness': nan}\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f78195172b0>, 'training_reps': 20, 'rank': 2, 'fitness': nan}\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f781950dbe0>, 'training_reps': 20, 'rank': 3, 'fitness': nan}\n",
      "deleted 2 elements from population\n",
      "population is back to 4 networks\n",
      "population after:\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "population before:\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f78194f4d60>, 'training_reps': 20, 'rank': 0, 'fitness': nan}\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f7819508700>, 'training_reps': 20, 'rank': 1, 'fitness': nan}\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f78195172b0>, 'training_reps': 20, 'rank': 2, 'fitness': nan}\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f781950dbe0>, 'training_reps': 20, 'rank': 3, 'fitness': nan}\n",
      "deleted 2 elements from population\n",
      "population is back to 4 networks\n",
      "population after:\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "population before:\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f78194f4d60>, 'training_reps': 20, 'rank': 0, 'fitness': nan}\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f7819508700>, 'training_reps': 20, 'rank': 1, 'fitness': nan}\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f78195172b0>, 'training_reps': 20, 'rank': 2, 'fitness': nan}\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f781950dbe0>, 'training_reps': 20, 'rank': 3, 'fitness': nan}\n",
      "deleted 2 elements from population\n",
      "population is back to 4 networks\n",
      "population after:\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "population before:\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f78194f4d60>, 'training_reps': 20, 'rank': 0, 'fitness': nan}\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f7819508700>, 'training_reps': 20, 'rank': 1, 'fitness': nan}\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f78195172b0>, 'training_reps': 20, 'rank': 2, 'fitness': nan}\n",
      "{'network': <malleable_network.GeneticNetwork object at 0x7f781950dbe0>, 'training_reps': 20, 'rank': 3, 'fitness': nan}\n",
      "deleted 2 elements from population\n",
      "population is back to 4 networks\n",
      "population after:\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n",
      "\n",
      "Genetic Network:\n",
      "MalleableLayer(sequential=True)\n",
      "Output Layer: Dense(units=1, activation=sigmoid)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(evolution.population)\n",
    "    evolution.iterate_population()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
